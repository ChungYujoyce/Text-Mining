{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5 classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dataset https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "\n",
    "Description: \n",
    "\n",
    "Pregnancies: Number of times pregnant <br>\n",
    "Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test<br>\n",
    "BloodPressure: Diastolic blood pressure (mm Hg)<br>\n",
    "SkinThickness: Triceps skin fold thickness (mm)<br>\n",
    "Insulin: 2-Hour serum insulin (mu U/ml)<br>\n",
    "BMI: Body mass index (weight in kg/(height in m)^2)<br>\n",
    "DiabetesPedigreeFunction: Diabetes pedigree function<br>\n",
    "Age: Age (years)<br>\n",
    "Outcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# visualize func\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "def visualize_tree(tree, name):\n",
    "    \"\"\"StringIO(): creates an object (empty in this case) to receive a string buffer (the tree will be created first as a string before as an image) in DOT (graph description language) format.\"\"\"\n",
    "    dot_data = StringIO()\n",
    "    \"\"\"export_graphviz(): exports the tree in DOT format, generating a representation of the decision tree, which is written into the ‘out_file’.\"\"\"\n",
    "    export_graphviz(tree, out_file = dot_data)\n",
    "    \"\"\"graph_from_dot_data(): will use the DOT object to create the graph.\"\"\"\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    graph.write_png(\"./\"+ name +\".png\")\n",
    "    Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "# load dataset\n",
    "data = pd.read_csv(\"./data/diabetes.csv\", header=0, names=col_names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicision tree Accuracy: 0.6796536796536796\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "X = data[feature_cols] # Features\n",
    "y = data.label # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "tree = []\n",
    "pred = []\n",
    "\n",
    "tree1 = DecisionTreeClassifier()\n",
    "tree1 = tree1.fit(X_train,y_train)\n",
    "pred1 = tree1.predict(X_test)\n",
    "print(\"Dicision tree Accuracy:\",metrics.accuracy_score(y_test, pred1))\n",
    "visualize_tree(tree1, \"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicision tree, Criterion = gini Accuracy: 0.7186147186147186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79       165\n",
      "           1       0.51      0.65      0.57        66\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       231\n",
      "   macro avg       0.67      0.70      0.68       231\n",
      "weighted avg       0.75      0.72      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree2 = DecisionTreeClassifier(criterion='gini', max_depth = 7)\n",
    "tree2.fit(X_train, y_train)\n",
    "pred2 = tree2.predict(X_test)\n",
    "print('Dicision tree, Criterion = gini Accuracy:', accuracy_score(y_test, pred2))\n",
    "visualize_tree(tree2, \"gini\")\n",
    "print(metrics.classification_report(pred2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicision tree, Criterion = entropy Accuracy: 0.7489177489177489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.73      0.83       188\n",
      "           1       0.41      0.81      0.55        43\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       231\n",
      "   macro avg       0.68      0.77      0.69       231\n",
      "weighted avg       0.85      0.75      0.77       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree3 = DecisionTreeClassifier(criterion='entropy', max_depth = 7, splitter='random')\n",
    "tree3.fit(X_train, y_train)\n",
    "pred3 = tree3.predict(X_test)\n",
    "print('Dicision tree, Criterion = entropy Accuracy:', accuracy_score(y_test, pred3))\n",
    "visualize_tree(tree3, \"entropy\")\n",
    "print(metrics.classification_report(pred3, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7835497835497836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84       158\n",
      "           1       0.64      0.74      0.68        73\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       231\n",
      "   macro avg       0.75      0.77      0.76       231\n",
      "weighted avg       0.80      0.78      0.79       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rtree = RandomForestClassifier(criterion = 'entropy', max_depth=4, random_state=0)\n",
    "Rtree.fit(X_train, y_train)\n",
    "Rpred = Rtree.predict(X_test)\n",
    "print('Random Forest Accuracy:', accuracy_score(y_test, Rpred))\n",
    "print(metrics.classification_report(Rpred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# confusion matrix need type list as input \n",
    "y_test_list = y_test.tolist() \n",
    "\n",
    "pred_list = []\n",
    "pred_list.append(pred1.tolist())\n",
    "pred_list.append(pred2.tolist())\n",
    "pred_list.append(pred3.tolist())\n",
    "pred_list.append(Rpred.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consufion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original decision tree:\n",
      "TP: 42 TN: 115 FP: 31 FN: 43\n",
      "Gini decision tree:\n",
      "TP: 43 TN: 123 FP: 23 FN: 42\n",
      "Entropy decision tree:\n",
      "TP: 35 TN: 138 FP: 8 FN: 50\n",
      "Random forest:\n",
      "TP: 54 TN: 127 FP: 19 FN: 31\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_list, pred_list[i]).ravel() # binary case\n",
    "    if(i==0): print(\"Original decision tree:\")\n",
    "    elif(i==1): print(\"Gini decision tree:\")\n",
    "    elif(i==2): print(\"Entropy decision tree:\")\n",
    "    else: print(\"Random forest:\")\n",
    "    print(\"TP:\", tp, \"TN:\",tn, \"FP:\",fp,\"FN:\" ,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAADmCAYAAAC6eEaGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xm4jfX+xvH7s/Y2y0xkKElpkpmiUqSJ5johhUZTSennNMrRoE4KKVNFkoYjdVKa5AgNhshQlMxDJMlQyba/vz/2tlOJtXb7u75Zz/t1XS7redbae997reu2fNYzmXNOAAAAAIDki4UOAAAAAABRxUAGAAAAAIEwkAEAAABAIAxkAAAAABAIAxkAAAAABMJABgAAAACBMJABAAAAQCAMZAAAAAAQCAMZAAAAAASS7uOb7ty41Pn4vvijxjU7hI4QGTPWTrHQGX6PriXHebW7hI4QKRNXTfxbdY2eJcd9de8KHSFSeq8YQ88iqtaxrUNHiIyF6z+Jq2dsIQMAAACAQBjIAAAAACAQBjIAAAAACISBDAAAAAACYSADAAAAgEAYyAAAAAAgEAYyAAAAAAiEgQwAAAAAAmEgAwAAAIBAGMgAAAAAIBAGMgAAAAAIhIEMAAAAAAJhIAMAAACAQBjIAAAAACAQBjIAAAAACISBDAAAAAACYSADAAAAgEAYyAAAAAAgEAYyAAAAAAiEgQwAAAAAAmEgAwAAAIBAGMgAAAAAIBAGMgAAAAAIhIEMAAAAAAJhIAMAAACAQBjIAAAAACAQBjIAAAAACISBDAAAAAACYSADAAAAgEAYyAAAAAAgEAYyAAAAAAiEgQwAAAAAAmEgAwAAAIBAGMgAAAAAIBAGMgAAAAAIhIEMAAAAAAJhIAMAAACAQBjIAAAAACAQBjIAAAAACISBDAAAAAACSQ8dIFnuvL+/Ppg+Q6VKltCrzw2RJL39/lQ98dRzWrpilcYOf0zHHX2kJGnNuvU6r811OqxKJUlSzWNr6J7bugXLngpisZhGvTVM3677Vj2u+qfufOQ2HV3zKMlMK5euUp/uD+qnH38KHRN5YG9d+/fjIzRl+idKz5euyhUrqO/tPVTsoKKa//li9e43UJLk5NS5Y1s1P7VxyPgHtFgspoFvDNTGbzaqd4feum3gbapes7oyMjL05dwvNbDXQO3K2BU6JvLA3no2aNizen/aR4pZTKVKFtd9d9yicmVLa+u27erV5yGtW/+tdmXsUvs2F+vCc1sE/g0OXN2nPaYd23+W25WpzF27NKzVXSpUvIguGdxNJSqV1ebV3+rlzgP185YfQ0fFX5TI+9mEt9/XM8+Py/naL79eppefHqQaR1YLFf+Alb9Afj372hDlz59faWlpemfC+xr88HC16XiJ2l13uapUrazGR7fQ5k0/hI6aZyKzheyCc87QkP59f7PuiMMP1WP336W6tY77w+MrV6ygcaMGa9yowQxjeeDyay7R8q9W5Cw/es/janvG1WrbvKPWr9mgSzteGDAd8tLeunZi/doaP3qIxj/7pA6rXFEjRr8oKauDLz41UONGDdbQR/qqz0ODlMHAkGvnX32+Vi5ZmbM8efxkXdv0WnVq3kn5C+bXWa3PCpgOeWlvPevQ9mKNf/ZJjRs1WKc2bqgnn3lekjR23OuqdlgVvTLqCT3zeD89PGi4du7cGSJ2yhh1eV8NOed2DWt1lySpSefztGz6Qg1qeouWTV+oJp3PC5wQeSGR97OWZ56e8//GB+6+VRUrHMwwlku/7PhFHS/qootOv0IXN7tCTU5vpJp1j9OnM+bp6ku7ac3KtaEj5rnIDGT1ah2v4sUO+s26aodVUdVDKwVKFB3lKpRV42aN9NrzE3LWbd/26yeHBQoWkJwLEQ0e7K1rjRvWVXp6mqSsLc7rN2yUJBUqWDBn/Y5ffpHMkhs2hZQpX0YNTm+gt8e+nbNu5uSZObcXz12sMhXKhIgGD/bWs6JFiuTc/umnn3PqZGba/uNPcs7px59+VvFiByktLS2ZcVPeUWfU0dxxUyVJc8dNVY0WdQMnQl5I5P1sT2++O0VnNz81KRlT1Y/Ze02l50tXenq6nHNatOBLrV21LnAyPyIzkCVqzbpvdEn7Lmrfpadmz10QOs4B7eZ7u2pQ3yHKzPzt0HXXo7008bPxOvSIKnrx6VcCpUOyjX/jHTU5sX7O8ryFi3R+2+t14ZWddHfPrjlvdEjM9b2v11P3P6XMzMw/3JeWnqZmFzXTrP/NCpAMyTRg6Eg1u7Cd3nhnsrpe006S1ObiVlq6fJVOO7+tLryyk3p1v0GxGG//ueXk1O65XrpuQl/VbX2aJKlomeLatmGzJGnbhs0qUqZ4yIhIkt+/n+321qQpOueMpskPlEJisZjGTRqtqQvf0kdTZmj+pwtDR/KKf5H3omzpknr3lWf1n5GD1bPbdbrt3n7atn176FgHpCbNT9T3Gzdr0fwv/3Dfv25+UOfWvljLv1qhM847PUA6JNvQUWOVlpamli1Oy1lX89gaem3MUL0wYoBGjH5JO3b8EjDhgalBswba/N1mLZm/ZK/3d7mvixZ8skALZ6T2Gxqkm65vr0njR+vcFqfp+XGvS5Kmz5itGtUP1+TXxmjcyMG6v/8TvKf9BU9fdK+Gnnunxlz1kOpfeYYObVAjdCQEsLf3MynrQ8ZCBQuq+uGHhQmWIjIzM3Vxs3Y6vVYrHV/nWB1R4/DQkbxiINuL/Pnzq0TxYpKkY2tUV+WKFbR85ZrAqQ5MNesfp5NbnKRXP3lB9z15t+o1qaN7B92Rc39mZqbe/e/7Ov2cUwKmRDK89ua7+mD6DPW75zbZXnZNrHZYFRUqWFBfLV2e/HAHuGPqHaNGZzTSyA9HqtfgXjqh8QnqOaCnJKlN9zYqXrq4hvUZFjglkuncFk313v+mS5LGv/Gump/aWGamKpUOUcUK5bVsxerACQ9cW7O3hG3/bosWvT1LFWsdrm0bf1DRciUkSUXLldD2jalzsgH80b7ezya+x+6KeWnrlm2aMX22mpx2YugoXjGQ7cWm7zdr166sEwusWrNOK1etVeWKFQKnOjA98cBwtap3qS5oeLnu6NRHs6Z9qnu63adKh1XMeczJLU7S8q9X7uO74EA37eNZemrMyxrU7x4VKlgwZ/3qtd/knMRj7TfrtXzlalWscHComAeskf1Gql2Ddmp/Uns92OVBfTb9Mz1808M68/IzVffUuurXtZ8cx2mmvBWrfv3gcPLUj3OOka5wcFl9PHuuJGnjpu+1fOVqVTqkfJCMB7p8hQoof5GCObernXK8NixercXvfapaF58sSap18cla/O6nIWPCoz97P5OyPmR+Z/JUBrK/qGTpEjqoWFFJWecZOPGUBlq2ZHnYUJ5F5rT3Pe95UDPnzNPmzVvU7IIr1PnqdiperKgeePRJbdr8gzr3vEc1qh+uYY/ep9lzF+jxEaOVlp6mtFhMd/fs+oeDOpF7ZqZ7BvxTRYoWkZn01edfq1+v/qFjIY/srWsjRr+oX3bu1LXds7aO7r6UxKfzFuqp0S8pPT1dsZjpzlu7qGQJjr3IK90e6KYNazao/6tZ/fpw4od6fsDzgVMhL+ytZ1M/mqnlK1fLYqZDypfT3T2zzhB8Q/s2uuO+R3Rhu05yzunmzh3pWS4VLVNM/xh2syQplp6m+a99qCVT5mnNZ0t16RPdVPsfTfXD2o16udPAwEmRFxJ5P5OkWXMX6OCyZfgQ/y8qe3AZ3T/wbsXSYorFYnr7tUma8u50tb3mMnXs0k5lypXS+Mlj9MGkD3VPj/tDx80T5uNT050bl/JRbJI0rtkhdITImLF2yt/uFIB0LTnOq90ldIRImbhq4t+qa/QsOe6re1foCJHSe8UYehZRtY5tHTpCZCxc/0lcPWOXRQAAAAAIhIEMAAAAAAJhIAMAAACAQBjIAAAAACAQBjIAAAAACORPT3tvZqX29YXOuU15HweIHroG+EfPAP/oGZA7+7oO2WxJTtLeTtfoJB3uJREQPXQN8I+eAf7RMyAX/nQgc85VTWYQIKroGuAfPQP8o2dA7uz3GDLLcoWZ3ZW9XMXMGviPBkQLXQP8o2eAf/QMSEw8J/V4QtKJktpkL2+VNNhbIiC66BrgHz0D/KNnQAL2dQzZbg2dc3XMbI4kOee+N7P8nnMBUUTXAP/oGeAfPQMSEM8Wsp1mlqasgzFlZmUlZXpNBUQTXQP8o2eAf/QMSEA8A9lASeMlHWxm90maJul+r6mAaKJrgH/0DPCPngEJ2O8ui865MWY2W1Kz7FUXOOe+8BsLiB66BvhHzwD/6BmQmHiOIZOkwpJ2b3ou5C8OEHl0DfCPngH+0TMgTvGc9v5uSaMklZJURtIzZnan72BA1NA1wD96BvhHz4DExLOFrLWk2s65nyXJzB6U9Kmkvj6DARFE1wD/6BngHz0DEhDPST2WSyq4x3IBSV97SQNE23LRNcC35aJngG/LRc+AuP3pFjIzG6Ss/X53SFpoZu9mL5+hrLPlAMgDdA3wj54B/tEzIHf2tcvirOy/Zyvr1KW7/c9bGiCa6BrgHz0D/KNnQC786UDmnBuVzCBAVNE1wD96BvhHz4Dc2e9JPcysuqQHJB2jPfYHds4d7jEXEDl0DfCPngH+0TMgMfGc1OMZSU9KypB0mqRnJY32GQqIKLoG+EfPAP/oGZCAeAayQs65SZLMObfCOddb0ul+YwGRRNcA/+gZ4B89AxIQz3XIfjazmKSvzKyrpDWSyvmNBUQSXQP8o2eAf/QMSEA8W8i6Syos6UZJdSW1k3SVz1BARNE1wD96BvhHz4AE7HcLmXNuZvbNbZI6+I0DRBddA/yjZ4B/9AxIzL4uDP26si7mt1fOufO8JAIihq4B/tEzwD96BuTOvraQ/TtpKYBoo2uAf/QM8I+eAbmwrwtDT0lmECCq6BrgHz0D/KNnQO7Ec1IPAAAAAIAHDGQAAAAAEAgDGQAAAAAEwlkWgcDoGuAfPQP8o2dA7sRzlsWLJJWX9Fz2cmtJyz1mAqKGrgH+0TPAP3oG5MJ+z7JoZv9yzp2yx12vm9kH3pMBEUHXAP/oGeAfPQNyJ55jyMqa2eG7F8ysqqSy/iIBkUXXAP/oGeAfPQMSsK9dFne7WdL/zGxp9vJhkq73lgiILroG+EfPAP/oGZCA/Q5kzrm3zKy6pBrZqxY553b4jQVED10D/KNngH/0DEjMfndZNLPCknpK6uqc+0xSFTNr6T0ZEDF0DfCPngH+0TMgMfHssviMpNmSTsxeXi3pZUkT/uwLCh1y8l9PhrjULF01dATkHbr2N3V2+dqhIyDv0LO/qVbl64SOgLxDz/7G7qzQNHQE/E48J/Wo5px7SNJOSXLO/STJvKYCoomuAf7RM8A/egYkIJ6B7BczK6TsC/2ZWTVJ7AcM5D26BvhHzwD/6BmQgHh2Wewt6S1Jlc1sjKTGkjr4DAVEVG/RNcC33qJngG+9Rc+AuMVzlsV3zGy2pEbK2tx8k3Nuo/dkQMTQNcA/egb4R8+AxMRzlsVJzrnvnHNvOOcmOOc2mtmkZIQDooSuAf7RM8A/egYk5k+3kJlZQUmFJZUxs5L69WDMYpIOSUI2IBLoGuAfPQP8o2dA7uxrl8XrJXVXVoFm69dSbZE02HMuIEroGuAfPQP8o2dALvzpQOacGyBpgJl1c84NSmImIFLoGuAfPQP8o2dA7sRz2vtMMyuxe8HMSppZZ4+ZgKiia4B/9Azwj54BCYhnILvWObd594Jz7ntJ1/qLBEQWXQP8o2eAf/QMSEA8A1nMzHKurm5maZLy+4sERBZdA/yjZ4B/9AxIQDwXhn5b0ktmNkRZV1y/QVkX+wOQt+ga4B89A/yjZ0AC4hnI/k9ZZ83ppKyz5bwjaYTPUEBE0TXAP3oG+EfPgATsdyBzzmVKejL7DwBP6BrgHz0D/KNnQGL2dWHol5xzl5nZfGVtbv4N51xNr8mAiKBrgH/0DPCPngG5s68tZDdl/90yGUGACKNrgH/0DPCPngG5sK8LQ6/L/ntF8uIA0UPXAP/oGeAfPQNyZ1+7LG7VXjY37+acK+YlERAxdA3wj54B/tEzIHf2tYXsIEkysz6SvpE0Wllnymkr6aCkpAMigK4B/tEzwD96BuROPBeGPtM594Rzbqtzbotz7klJF/sOBkQQXQP8o2eAf/QMSEA8A9kuM2trZmlmFjOztpJ2+Q4GRBBdA/yjZ4B/9AxIQDwDWRtJl0lan/3n0ux1APIWXQP8o2eAf/QMSEA8F4ZeLul8/1GAaKNrgH/0DPCPngGJ2e8WMjM70swmmdmC7OWaZnan/2hAtNA1wD96BvhHz4DExLPL4nBJ/5S0U5Kcc/MkXe4zFBBRdA3wj54B/tEzIAHxDGSFnXMzfrcuw0cYIOLoGuAfPQP8o2dAAuIZyDaaWTVlX+jPzC6RtM5rKiCa6BrgHz0D/KNnQAL2e1IPSV0kDZNUw8zWSFqmrAv8AchbdA3wj54B/tEzIAH7HMjMLCapnnOuuZkVkRRzzm1NTjQgOuga4B89A/yjZ0Di9rnLonMuU1LX7NvbKRTgB10D/KNngH/0DEhcPMeQvWtmt5pZZTMrtfuP92RA9NA1wD96BvhHz4AExHMMWcfsv7vssc5JOjzv4wCRRtcA/+gZ4B89AxKw34HMOVc1GUGAqKNrgH/0DPCPngGJ2e9AZmYFJXWW1ERZn25MlTTEOfez52xApNA1wD96BvhHz4DExLPL4rOStkoalL3cWtJoSZf6CgVEFF0D/KNngH/0DEhAPAPZUc65E/ZYnmxmn/kKBEQYXQP8o2eAf/QMSEA8Z1mcY2aNdi+YWUNJ0/1FAiKLrgH+0TPAP3oGJCCeLWQNJV1pZiuzl6tI+sLM5ktyzrma3tIB0ULXAP/oGeAfPQMSEM9Adpb3FAAkugYkAz0D/KNnQALiOe39imQEAaKOrgH+0TPAP3oGJCaeY8gAAAAAAB7Es8tiyilQoID+9/445S9QQOnpaXrllTd0b59H1LlTe93Y7RodcURVHVzhOH333feho6aMWCym594aoW+/+VY3Xfl/6jv4bh1Ts4YyMjK0cM4Xuu+2h5SRsSt0TOShSpUO0cinB+jg8mWVmZmpESPGaNDjT+ne3j3VqlULZWY6fbthozpec7PWrVsfOm5KiMVi6j/hUW1a/536dOijbg/dqOo1q0smrV22Vo/1eFQ//8hlgFLdTTdeq44dW8s5pwULFunqa3pox44doWOlhHwF8um+lx9Uev58SktP00dvTtcL/Z9Xt0e669iGx+nHrdslSQNveUzLP18WOC3y0vBhj+jcc5prw7cbVat2M0lSzZrH6InHH1SRooW1YsVqtbuyq7Zu3RY4aWroPu0x7dj+s9yuTGXu2qVhre7Kue+k685Rizva6qFa1+vH71Pj+Y7kFrIdO3aoeYvLVLfeGapbr4XObNFUDRvU0YcfzdSZZ1+u5ctXhY6Yclpfe6mWffXrHgwTx72ji05uo8tOu1IFChbQBW1aBUwHHzIyMtTztnt1fM2matyklTp1aq+jj66ufz/ypOrUPUP16rfQG2++pzvvuDl01JTRquN5Wr3k13+/RvQZrhvP6qYbz+ymb9d8q5btWwZMh2Q45JDy6tqloxo2Oke1ajdTWlqa/nHZ+aFjpYydO3bq7svvUI+zblSPs25U7VPr6MjaR0mSRt3/tHqcfZN6nH0Tw1gKevbZl3Ruy7a/WTd0yMO6/Y77VbtOc7366kTdekunQOlS06jL+2rIObf/ZhgrVqGUDm9yvDav3hgwWd6L5EAmSdu3/yhJypcvXen58sk5p7lzF2rFitWBk6WechXK6uRmJ+rV51/PWTf9/Y9zbi+c+7kOPqRciGjw6JtvNmjO3AWSpG3btmvRoq9U8ZDyv/n0sEiRwnLOhYqYUkqXL636zerrnRfeyVn307afcm7nL5if5zoi0tPTVahQQaWlpalwoUJat+6b0JFSyu6tzGnp6UpLT6dXETF12ifa9P3m36w76shq+mBq1v9n3ps0VRdeeE6IaJFy1t3t9O4DY6UU611kB7JYLKZZM9/RujXzNGnSB5oxc07oSCnr1j43akDfJ5WZ+cfypKen6ZxLztSHkz/ey1ciVRx6aCXVOuE4fTIjq2f/6vN/Wvb1TLVufaF63/tw4HSp4dre1+mZ+5/+Q89u+vdNenb2aFWqVkkTnpkQKB2SZe3ab9T/0SFa9vUMrV45Rz9s2aJ33/sgdKyUEovF1H/iAI2cM1qfTZujr+Z+KUlq27OdHn17oDrcfY3S80fyiJDIWbhwsVq1aiFJuuTilqpc6ZDAiVKHk1O753rpugl9Vbf1aZKko5rX0ZZvNmn9Fyv389UHnsgOZJmZmapXv4UOrVpP9evV1rHHHhU6Uko6uflJ2rRxs76Yt3iv9/d68BbN+fgzzflkXpKTIVmKFCmsl14crh633pOzdeyuu/uparX6Gjt2vLp07hA44YGvfrP6+mHjZn09/+s/3Dfg1gFqX/8qrV6ySk1anRwgHZKpRIniOq/VmTriyEaqfGgdFSlSWG3aXBQ6VkrJzMxUj7Nv0jUNO6j6CUeqypFV9Fy/Uep6Wif1bNVDB5Uoqos6XRI6JpLgmut6qPMN7fXJxxN10EFF9MsvO0NHShlPX3Svhp57p8Zc9ZDqX3mGDm1QQyd3PV+T+/8ndDQvIjuQ7fbDD1s05YMPdWaLpqGjpKQTGhyvU1s01oQZL+uBIb1Vr0ld9X08a1/g63p0UMnSJfTIPYMCp4Qv6enpevnF4Ro7drxefXXiH+4f+8J4dvHIA0fXO0YNzmioEdOf0m2P36aaJ9VUj8duybk/MzNTU1+fqsbnnBQwJZKhWbOTtWz5Sm3cuEkZGRka/+pEndioXuhYKenHLdu14OP5qt20rr7fkHUSsIxfMjTppfdUvdaRgdMhGRYv/lpnn9tGDRudrRdefE1Lly4PHSllbN2QtXvo9u+2aNHbs3RooxoqWbmsOk18QN2nPaZiFUrp+jfuU9GyxQMnzRuRHMjKlCml4sWLSZIKFiyoZqefrMWL//jJMv66x+8fqrPrXqSWDS7VP2/orVnTZuvOrv/SBW1a6sSmDXR7p97sf5/Chg97RF8sWqLHBgzLWXfEEVVzbrdq2YLu5YFn+41Sh4btdU3jq/VQ14c078N56t/9EVU4tELOYxo0b6DVSzhGNtWtWrlGDRvWUaFCBSVJp5/WRIsWfRU4VeooVqqYChcrIknKXyC/TmhSS2u+Xq2S5UrmPKbhmY20cjGX4YqCsmVLS5LMTLf/8yYNHTY6cKLUkK9QAeUvUjDndrVTjtfaz5bq4bqd9ViT7nqsSXdtWbdJQ8+9Q9u+/SFw2rwRyZ2cK1Q4WE8/9ZjS0mKKxWL6z39e1xtvvqeuXTrq1ls6q3z5spoz+z1NfOt9XX9Dz9BxU9Lt/W7VutXrNfL1oZKk99+couGPjgwbCnmq8Un11e6KSzRv/ueaNTPrRBN33fWgOnS4XEceWU2ZmZlauXKNOnfpFThpajIzdX/0ZhUuWlhmpmWfL9MTdwwOHQuezZg5R6+88oZmznhbGRkZmjt3oYaPGBM6VsooWa6UbuzfXbHs/z9MnzBNsybNVJ+xfVWsdPGsri1cqiG3PxE6KvLYc6MH69RTTlSZMqW0fOks3dvn3ypatIg6dWovSXr11Tc1ctSLYUOmiKJliukfw7LOwBxLT9P81z7UkimpfWiL+dg6kZ6/Ips8kqRm6ar7fxDyxKfrplnoDL9H15Lj7PK1Q0eIlNdXTvhbdY2eJUer8nVCR4iU8Stfp2cRdWeFpqEjREbvFWPi6lkkd1kEAAAAgL8DBjIAAAAACISBDAAAAAACYSADAAAAgEAYyAAAAAAgEAYyAAAAAAiEgQwAAAAAAmEgAwAAAIBAGMgAAAAAIBAGMgAAAAAIhIEMAAAAAAJhIAMAAACAQBjIAAAAACAQBjIAAAAACISBDAAAAAACYSADAAAAgEAYyAAAAAAgEAYyAAAAAAiEgQwAAAAAAmEgAwAAAIBAGMgAAAAAIBAGMgAAAAAIhIEMAAAAAAJhIAMAAACAQBjIAAAAACAQBjIAAAAACISBDAAAAAACYSADAAAAgEAYyAAAAAAgEAYyAAAAAAiEgQwAAAAAAmEgAwAAAIBAGMgAAAAAIBAGMgAAAAAIhIEMAAAAAAJhIAMAAACAQBjIAAAAACAQBjIAAAAACISBDAAAAAACYSADAAAAgEAYyAAAAAAgEHPOhc7wt2Fm1znnhoXOEQU819HFa588PNfRxWufPDzX0cbrnzyp/Fyzhey3rgsdIEJ4rqOL1z55eK6ji9c+eXiuo43XP3lS9rlmIAMAAACAQBjIAAAAACAQBrLfSsn9Uv+meK6ji9c+eXiuo4vXPnl4rqON1z95Uva55qQeAAAAABAIW8gAAAAAIBAGMgAAAAAIhIFMkpmdZWaLzWyJmfUKnSeVmdnTZrbBzBaEzoLko2vJQc+ijZ4lBz2LNnqWPFHoWuQHMjNLkzRY0tmSjpHU2syOCZsqpY2UdFboEEg+upZUI0XPIomeJdVI0bNIomdJN1Ip3rXID2SSGkha4pxb6pz7RdILks4PnCllOec+kLQpdA4EQdeShJ5FGj1LEnoWafQsiaLQNQYyqaKkVXssr85eByBv0TXAP3oG+EfPkKcYyCTbyzquBQDkPboG+EfPAP/oGfIUA1nWpxqV91iuJGltoCxAKqNrgH/0DPCPniFPMZBJMyVVN7OqZpZf0uWS/hs4E5CK6BrgHz0D/KNnyFORH8iccxmSukp6W9IXkl5yzi0Mmyp1mdlYSR9JOsrMVpvZ1aEzITnoWvLQs+iiZ8lDz6KLniVXFLpmzrHLKwAAAACEEPktZAAAAAAQCgMZAAAAAATCQAYAAAAAgTCQAQAAAEAgDGQAAAAAEAgDmWdmVsLMOnv8/u3N7PH9PKa3md2a4Pfd9teSAclF1wD/6BngHz2LHgYy/0pI2mupzCwtyVmAVEbXAP/oGeAfPYsYBjL/HpRUzczmmtnDZtbUzCab2fOS5pvZYWa2YPeDzexWM+udfbuamb1lZrM3TCm4AAACNklEQVTNbKqZ1djXDzKzVmb2iZnNMbP3zOzgPe4+wczeN7OvzOzaPb6mp5nNNLN5ZnZv3v7qQFLRNcA/egb4R88iJj10gAjoJek451wtSTKzppIaZK9bZmaH7eNrh0m6wTn3lZk1lPSEpNP38fhpkho555yZXSPpNkm3ZN9XU1IjSUUkzTGzNyQdJ6l6dh6T9F8zO8U590GuflMgLLoG+EfPAP/oWcQwkIUxwzm3bF8PMLOikk6S9LKZ7V5dYD/ft5KkF82sgqT8kvb8Ga85536S9JOZTVZWkZpIaiFpTvZjiiqrZJQKqYKuAf7RM8A/epbCGMjC2L7H7Qz9dtfRgtl/xyRt3v3pSJwGServnPtv9qcpvfe4z/3usU5Zn2w84JwbmsDPAA4kdA3wj54B/tGzFMYxZP5tlXTQPu5fL6mcmZU2swKSWkqSc26LpGVmdqkkWZYT9vOziktak337qt/dd76ZFTSz0pKaSpop6W1JHbM/UZGZVTSzcvH/asDfCl0D/KNngH/0LGLYQuaZc+47M5ueffDlRElv/O7+nWbWR9InytpMvGiPu9tKetLM7pSUT9ILkj7bx4/rrazN1GskfSyp6h73zcj+2VUk/cs5t1bSWjM7WtJH2Zu2t0m6QtKGXP66QDB0DfCPngH+0bPoMed+vzUSAAAAAJAM7LIIAAAAAIEwkAEAAABAIAxkAAAAABAIAxkAAAAABMJABgAAAACBMJABAAAAQCAMZAAAAAAQyP8DiPNBX+msTkwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn  as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = []\n",
    "f, ax = plt.subplots(1,4, figsize = (15,10))\n",
    "\n",
    "for i in range(4):\n",
    "    g1 = sns.heatmap(confusion_matrix(y_test_list, pred_list[i]).T, square=True, annot=True, fmt='d', cbar=False,ax=ax[i])\n",
    "    g1.set_ylabel('predicted label')\n",
    "    g1.set_xlabel('true label')\n",
    "    g1.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Present the results of the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 2 part by class (pos/neg)\n",
    "neg = data[data['label'] == 0]\n",
    "pos = data[data['label'] == 1]\n",
    "\n",
    "def show_info_in_diff_classes(data,Class, X_train, X_test, y_train, y_test, y_score, tree):\n",
    "    \n",
    "    tree = tree.fit(X_train, y_train)\n",
    "    pred = tree.predict(X_test)\n",
    "    pred_list = pred.tolist()\n",
    "    y_test_list = y_test.tolist() \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_list, pred_list).ravel() # binary case\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    # need to transform y_test label into one hot encoding\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "    ohe_data = onehotencoder.fit_transform(y_test).toarray() \n",
    "    ohe_data = np.array(ohe_data)\n",
    "    \n",
    "    roc_area = roc_auc_score(ohe_data, y_score)\n",
    "    prc_area = average_precision_score(ohe_data, y_score)\n",
    "    \n",
    "    d = {'samples': len(data), 'classes': Class, 'attributes': 8,\n",
    "          'TP':tp, 'TN':tn, 'FP':fp, 'FN':fn, 'ROC area': roc_area, 'PRC area': prc_area}\n",
    "\n",
    "    df = pd.DataFrame(d, index=[0])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Tree type  # samples classes  # attributes  TP   TN  FP  FN  ROC area  PRC area\n",
      "      Original        268     pos             8  42  113  33  43  0.627196  0.577585\n",
      "          Gini        268     pos             8  45  123  23  40  0.684932  0.646590\n",
      "       Entropy        268     pos             8  46  118  28  39  0.765955  0.719416\n",
      " Random Forest        268     pos             8  54  127  19  31  0.847703  0.838684\n",
      "\n",
      "\n",
      "     Tree type  # samples classes  # attributes  TP   TN  FP  FN  ROC area  PRC area\n",
      "      Original        500     neg             8  44  117  29  41  0.634045  0.583172\n",
      "          Gini        500     neg             8  44  125  21  41  0.724456  0.678317\n",
      "       Entropy        500     neg             8  44  132  14  41  0.713054  0.673748\n",
      " Random Forest        500     neg             8  54  127  19  31  0.847703  0.838684\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "# process data first\n",
    "X = pos[feature_cols] # Features\n",
    "y = pos.label # Target variable\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X = neg[feature_cols] # Features\n",
    "y = neg.label # Target variable\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#pd.DataFrame.from_dict(data)\n",
    "res1 = show_info_in_diff_classes(pos,\"pos\", X_train, X_test, y_train, y_test, tree1.predict_proba(X_test), tree1)\n",
    "res2 = show_info_in_diff_classes(pos,\"pos\", X_train, X_test, y_train, y_test, tree2.predict_proba(X_test), tree2)\n",
    "res3 = show_info_in_diff_classes(pos,\"pos\", X_train, X_test, y_train, y_test, tree3.predict_proba(X_test), tree3)\n",
    "res4 = show_info_in_diff_classes(pos,\"pos\", X_train, X_test, y_train, y_test, Rtree.predict_proba(X_test), Rtree)\n",
    "\n",
    "frames = [res1, res2, res3, res4]\n",
    "result_pos = pd.concat(frames)\n",
    "result_pos.insert(loc=0, column='Tree type', value=['Original','Gini', 'Entropy', 'Random Forest'])\n",
    "print(result_pos.to_string(index=False))\n",
    "print('\\n')    \n",
    "\n",
    "res5 = show_info_in_diff_classes(neg,\"neg\", X_train, X_test, y_train, y_test, tree1.predict_proba(X_test), tree1)\n",
    "res6 = show_info_in_diff_classes(neg,\"neg\", X_train, X_test, y_train, y_test, tree2.predict_proba(X_test), tree2)\n",
    "res7 = show_info_in_diff_classes(neg,\"neg\", X_train, X_test, y_train, y_test, tree3.predict_proba(X_test), tree3)\n",
    "res8 = show_info_in_diff_classes(neg,\"neg\", X_train, X_test, y_train, y_test, Rtree.predict_proba(X_test), Rtree)\n",
    "\n",
    "frames = [res5, res6, res7, res8]\n",
    "result_neg = pd.concat(frames)\n",
    "result_neg.insert(loc=0, column='Tree type', value=['Original','Gini', 'Entropy', 'Random Forest'])\n",
    "print(result_neg.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "# need to transform y_test label into one hot encoding\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "ohe_data = onehotencoder.fit_transform(y_test).toarray() \n",
    "ohe_data = np.array(ohe_data)\n",
    "\n",
    "\n",
    "def plot_ROC(y_score, title):\n",
    "\n",
    "    n_classes = 2\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(ohe_data[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ohe_data.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    lw = 2\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ROC(tree1.predict_proba(X_test), \"Original Decision Tree without any parameter changed\")\n",
    "plot_ROC(tree2.predict_proba(X_test), \"Gini Decision Tree\")\n",
    "plot_ROC(tree3.predict_proba(X_test), \"Entropy Decision Tree\")\n",
    "plot_ROC(Rtree.predict_proba(X_test), \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analyzation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
